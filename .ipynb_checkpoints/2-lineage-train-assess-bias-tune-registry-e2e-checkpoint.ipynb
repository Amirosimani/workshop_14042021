{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Train, Check Bias, Tune, Record Lineage, and Register a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aud-overview'> </a>\n",
    "\n",
    "## [Overview](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 0 : Overview, Architecture and Data Exploration](./0-AutoClaimFraudDetection.ipynb)\n",
    "* [Notebook 1: Data Prep, Process, Store Features](./1-data-prep-e2e.ipynb)\n",
    "* **[Notebook 2: Train, Check Bias, Tune, Record Lineage, and Register a Model](./2-lineage-train-assess-bias-tune-registry-e2e.ipynb)**\n",
    "  * **[Architecture](#train)**\n",
    "  * **[Train a model using XGBoost](#aud-train-model)**\n",
    "  * **[Model lineage with artifacts and associations](#model-lineage)**\n",
    "  * **[Evaluate the model for bias with Clarify](#check-bias)**\n",
    "  * **[Deposit Model and Lineage in SageMaker Model Registry](#model-registry)**\n",
    "* [Notebook 3: Mitigate Bias, Train New Model, Store in Registry](./3-mitigate-bias-train-model2-registry-e2e.ipynb)\n",
    "* [Notebook 4: Deploy Model, Run Predictions](./4-deploy-run-inference-e2e.ipynb)\n",
    "* [Notebook 5 : Create and Run an End-to-End Pipeline to Deploy the Model](./5-pipeline-e2e.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will show how you can assess pre-training and post-training bias with SageMaker Clarify, Train the Model using XGBoost on SageMaker, and then finally deposit it in the Model Registry, along with the Lineage of Artifacts that were created along the way: data, code and model metadata.\n",
    "\n",
    "In this second model, you will fix the gender imbalance in the dataset using SMOTE and train another model using XGBoost. This model will also be saved to our registry and eventually approved for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='train'> </a>\n",
    "## Architecture for the ML Lifecycle Stage: Train, Check Bias, Tune, Record Lineage, Register Model\n",
    "[overview](#overview)\n",
    "___\n",
    "\n",
    "![train-assess-tune-register](./images/e2e-2-pipeline-v3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required and/or update libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -Uq pip\n",
    "!python -m pip install -q awswrangler==2.2.0 imbalanced-learn==0.7.0 sagemaker==2.23.1 boto3==1.16.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the update to the current kernel, run the following code to refresh the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stored variables\n",
    "Run the cell below to load any prevously created variables. You should see a print-out of the existing variables. If you don't see anything you may need to create them again or it may be your first time running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bucket                              -> 'sagemaker-us-east-1-171928886260'\n",
      "claims_fg_name                      -> 'fraud-detect-demo-claims'\n",
      "claims_table                        -> 'fraud-detect-demo-claims-1618346734'\n",
      "clarify_bias_job_1_name             -> 'Clarify-Bias-2021-04-13-21-59-54-456'\n",
      "col_order                           -> ['fraud', 'customer_education', 'incident_type_bre\n",
      "customers_fg_name                   -> 'fraud-detect-demo-customers'\n",
      "customers_table                     -> 'fraud-detect-demo-customers-1618346737'\n",
      "database_name                       -> 'sagemaker_featurestore'\n",
      "hyperparameters                     -> {'max_depth': '3', 'eta': '0.2', 'objective': 'bin\n",
      "model_1_name                        -> 'fraud-detect-demo-xgboost-pre-smote'\n",
      "model_2_name                        -> 'fraud-detect-demo-xgboost-post-smote'\n",
      "mpg_name                            -> 'fraud-detect-demo'\n",
      "prefix                              -> 'fraud-detect-demo'\n",
      "test_data_uri                       -> 's3://sagemaker-us-east-1-171928886260/fraud-detec\n",
      "train_data_uri                      -> 's3://sagemaker-us-east-1-171928886260/fraud-detec\n",
      "training_job_1_name                 -> 'sagemaker-xgboost-2021-04-13-21-54-46-144'\n",
      "training_job_2_name                 -> 'sagemaker-xgboost-2021-04-14-03-26-41-416'\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Important</font>: You must have run the previous sequancial notebooks to retrieve variables using the StoreMagic command.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "from model_package_src.inference_specification import InferenceSpecification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set region, boto3 and SageMaker SDK variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "#You can change this to a region of your choice\n",
    "import sagemaker\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(region_name=region)\n",
    "\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used for parameterizing the notebook run\n",
    "estimator_output_path = f's3://{bucket}/{prefix}/training_jobs'\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "bias_report_1_output_path = f's3://{bucket}/{prefix}/clarify-output/bias_1'\n",
    "\n",
    "\n",
    "xgb_model_name = 'xgb-insurance-claims-fraud-model'\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m5.large\"\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.c5.large\"\n",
    "batch_transform_instance_count = 1\n",
    "batch_transform_instance_type = \"ml.c5.large\"\n",
    "claify_instance_count = 1\n",
    "clairfy_instance_type = 'ml.c5.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aud-train-model'></a>\n",
    "## Train a model using XGBoost\n",
    "\n",
    "[overview](#overview)\n",
    "___\n",
    "Once the training and test datasets have been persisted in S3, you can start training a model by defining which SageMaker Estimator you'd like to use. For this guide, you will use the [XGBoost Open Source Framework](https://sagemaker.readthedocs.io/en/stable/frameworks/xgboost/xgboost.html) to train your model. This estimator is accessed via the SageMaker SDK, but mirrors the open source version of the [XGBoost Python package](https://xgboost.readthedocs.io/en/latest/python/index.html). Any functioanlity provided by the XGBoost Python package can be implemented in your training script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the hyperparameters\n",
    "These are the parameters which will be sent to our training script in order to train the model. Although they are all defined as \"hyperparameters\" here, they can encompass XGBoost's [Learning Task Parameters](https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters), [Tree Booster Parameters](https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster), or any other parameters you'd like to configure for XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'hyperparameters' (dict)\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "        \"max_depth\": \"3\",\n",
    "        \"eta\": \"0.2\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"num_round\": \"100\",\n",
    "}\n",
    "%store hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and fit the estimator\n",
    "If you want to explore the breadth of functionailty offered by the SageMaker XGBoost Framework you can read about all the configuration parameters by referencing the inhereting classes. The XGBoost class inherets from the Framework class and Framework inherets from the EstimatorBase class:\n",
    "* [XGBoost Estimator documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/xgboost/xgboost.html#sagemaker.xgboost.estimator.XGBoost)\n",
    "* [Framework documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.Framework)\n",
    "* [EstimatorBase documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                              output_path = estimator_output_path,\n",
    "                                              hyperparameters = hyperparameters,\n",
    "                                              role = sagemaker_role,\n",
    "                                              instance_count = train_instance_count,\n",
    "                                              instance_type = train_instance_type,\n",
    "                                              framework_version = \"1.0-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using previous training job: sagemaker-xgboost-2021-04-13-21-54-46-144\n"
     ]
    }
   ],
   "source": [
    "if 'training_job_1_name' not in locals():\n",
    "    \n",
    "    train_input = TrainingInput(train_data_uri, content_type='csv')\n",
    "\n",
    "    xgb_estimator.fit(inputs = {'train': train_input})\n",
    "    training_job_1_name = xgb_estimator.latest_training_job.job_name\n",
    "    %store training_job_1_name\n",
    "    \n",
    "else:\n",
    "    print(f'Using previous training job: {training_job_1_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-14 03:50:28 Starting - Starting the training job...\n",
      "2021-04-14 03:50:32 Starting - Launching requested ML instancesProfilerReport-1618372228: InProgress\n",
      "......\n",
      "2021-04-14 03:51:48 Starting - Preparing the instances for training......\n",
      "2021-04-14 03:52:58 Downloading - Downloading input data...\n",
      "2021-04-14 03:53:29 Training - Downloading the training image...\n",
      "2021-04-14 03:54:00 Training - Training image download completed. Training in progress...\u001b[34m[2021-04-14 03:54:02.363 ip-10-0-112-188.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 4001 rows and 45 columns\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.02574\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.02624\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.02599\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.02599\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.02599\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.02599\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.02599\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.02599\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.02599\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.02599\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.02599\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.02599\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.02574\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.02549\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.02499\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.02499\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.02474\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.02474\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.02474\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.02474\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.02474\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.02474\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.02474\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.02474\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.02474\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.02474\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.02449\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.02449\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.02449\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.02449\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.02424\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.02424\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.02399\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.02399\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.02399\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.02399\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.02374\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.02299\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.02274\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.02274\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.02274\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.02274\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.02274\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.02200\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.02200\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.02200\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.02175\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.02150\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.02099\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.02150\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.02124\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.02124\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.02124\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.02124\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.02099\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.02099\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.02099\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.02150\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.02124\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.02074\u001b[0m\n",
      "\n",
      "2021-04-14 03:54:29 Uploading - Uploading generated training model\n",
      "2021-04-14 03:54:29 Completed - Training job completed\n",
      "Training seconds: 76\n",
      "Billable seconds: 76\n"
     ]
    }
   ],
   "source": [
    "train_input = TrainingInput(train_data_uri, content_type='csv')\n",
    "\n",
    "xgb_estimator.fit(inputs = {'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model-lineage'></a>\n",
    "## Model lineage with artifacts and associations\n",
    "\n",
    "[Overview](#aud-overview)\n",
    "___\n",
    "Amazon SageMaker ML Lineage Tracking creates and stores information about the steps of a machine learning (ML) workflow from data preparation to model deployment. With the tracking information you can reproduce the workflow steps, track model and dataset lineage, and establish model governance and audit standards. With SageMaker Lineage Tracking data scientists and model builders can do the following:\n",
    "* Keep a running history of model discovery experiments.\n",
    "* Establish model governance by tracking model lineage artifacts for auditing and compliance verification.\n",
    "* Clone and rerun workflows to experiment with what-if scenarios while developing models.\n",
    "* Share a workflow that colleagues can reproduce and enhance (for example, while collaborating on solving a business problem).\n",
    "* Clone and rerun workflows with additional debugging or logging routines, or new input variations for troubleshooting issues in production models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='register-artifacts'></a>\n",
    "### Register artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the `xgb_estimator` object retains much the data we need to learn about how the model was trained, it is, in fact, an ephermeral object which SageMaker does not persist and cannot be re-instantiated at a later time. Although we lose some of its convieneces once it is gone, we can still get back all the data we need by accessing the training jobs it once created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_1_info = sagemaker_boto_client.describe_training_job(TrainingJobName=training_job_1_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing artifact: arn:aws:sagemaker:us-east-1:171928886260:artifact/f68956e1766511bd679be4e583709f75\n"
     ]
    }
   ],
   "source": [
    "# return any existing artifact which match the our training job's code arn\n",
    "# ====>\n",
    "\n",
    "# extract the training code uri and check if it's an exisiting artifact\n",
    "code_s3_uri = training_job_1_info['HyperParameters']['sagemaker_submit_directory']\n",
    "\n",
    "matching_artifacts = list(sagemaker.lineage.artifact.Artifact.list(\n",
    "    source_uri=code_s3_uri, \n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "# use existing arifact if it's already been created, otherwise create a new artifact\n",
    "if matching_artifacts:\n",
    "    code_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {code_artifact.artifact_arn}')\n",
    "else:\n",
    "    code_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name='TrainingScript',\n",
    "        source_uri=code_s3_uri,\n",
    "        artifact_type='Code',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {code_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing artifact: arn:aws:sagemaker:us-east-1:171928886260:artifact/c041d369c923ba61dd513353ff3684d3\n"
     ]
    }
   ],
   "source": [
    "training_data_s3_uri = training_job_1_info['InputDataConfig'][0]['DataSource']['S3DataSource']['S3Uri']\n",
    "\n",
    "matching_artifacts = list(sagemaker.lineage.artifact.Artifact.list(\n",
    "    source_uri=training_data_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    training_data_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {training_data_artifact.artifact_arn}')\n",
    "else:\n",
    "    training_data_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name='TrainingData',\n",
    "        source_uri=training_data_s3_uri,\n",
    "        artifact_type='Dataset',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {training_data_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing artifact: arn:aws:sagemaker:us-east-1:171928886260:artifact/d9ce7a8586d175347fdc4159d5930a3c\n"
     ]
    }
   ],
   "source": [
    "trained_model_s3_uri = training_job_1_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "matching_artifacts = list(sagemaker.lineage.artifact.Artifact.list(\n",
    "    source_uri=trained_model_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    model_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {model_artifact.artifact_arn}')\n",
    "else:\n",
    "    model_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name='TrainedModel',\n",
    "        source_uri=trained_model_s3_uri,\n",
    "        artifact_type='Model',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {model_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Set-artifact-associations'></a>\n",
    "### Set artifact associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component = sagemaker_boto_client.describe_trial_component(TrialComponentName=training_job_1_name+'-aws-training-job')\n",
    "trial_component_arn = trial_component['TrialComponentArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association already exists with Code\n",
      "Association already exists with DataSet\n"
     ]
    }
   ],
   "source": [
    "input_artifacts = [code_artifact, training_data_artifact]\n",
    "\n",
    "for a in input_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type='ContributedTo',\n",
    "            sagemaker_session=sagemaker_session)\n",
    "        print(f\"Association with {a.artifact_type}: SUCCEESFUL\")\n",
    "    except:\n",
    "        print(f\"Association already exists with {a.artifact_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association already exists with Model\n"
     ]
    }
   ],
   "source": [
    "output_artifacts = [model_artifact]\n",
    "\n",
    "for a in output_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type='Produced',\n",
    "            sagemaker_session=sagemaker_session)\n",
    "        print(f\"Association with {a.artifact_type}: SUCCESSFUL\")\n",
    "    except:\n",
    "        print(f\"Association already exists with {a.artifact_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='check-bias'></a>\n",
    "## Evaluate model for bias with Clarify\n",
    "\n",
    "[overview](#aud-overview)\n",
    "___\n",
    "Amazon SageMaker Clarify helps improve your machine learning (ML) models by detecting potential bias and helping explain the predictions that models make. It helps you identify various types of bias in pretraining data and in posttraining that can emerge during model training or when the model is in production. SageMaker Clarify helps explain how these models make predictions using a feature attribution approach. It also monitors inferences models make in production for bias or feature attribution drift. The fairness and explainability functionality provided by SageMaker Clarify provides components that help AWS customers build less biased and more understandable machine learning models. It also provides tools to help you generate model governance reports which you can use to inform risk and compliance teams, and external regulators. \n",
    "\n",
    "You can reference the [SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-fairness-and-explainability.html) for more information about SageMaker Clarify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model from estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_1_name' (str)\n",
      "Model fraud-detect-demo-xgboost-pre-smote already exists.\n"
     ]
    }
   ],
   "source": [
    "model_1_name = f'{prefix}-xgboost-pre-smote'\n",
    "%store model_1_name\n",
    "model_matches = sagemaker_boto_client.list_models(NameContains=model_1_name)['Models']\n",
    "\n",
    "if not model_matches:\n",
    "    \n",
    "    model_1 = sagemaker_session.create_model_from_job(\n",
    "        name=model_1_name,\n",
    "        training_job_name=training_job_1_info['TrainingJobName'],\n",
    "        role=sagemaker_role,\n",
    "        image_uri=training_job_1_info['AlgorithmSpecification']['TrainingImage'])\n",
    "else:\n",
    "    \n",
    "    print(f\"Model {model_1_name} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bias-v1'></a>\n",
    "### Check for data set bias and model bias\n",
    "\n",
    "With SageMaker, we can check for pre-training and post-training bias. Pre-training metrics show pre-existing bias in that data, while post-training metrics show bias in the predictions from the model. Using the SageMaker SDK, we can specify which groups we want to check bias across and which metrics we'd like to show. \n",
    "\n",
    "To run the full Clarify job, you must un-comment the code in the cell below. Running the job will take ~15 minutes. If you wish to save time, you can view the results in the next cell after which loads a pre-generated output if no bias job was run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = wr.s3.read_csv(training_data_s3_uri).columns.to_list()\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role=sagemaker_role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    sagemaker_session=sagemaker_session)\n",
    "\n",
    "bias_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_uri,\n",
    "    s3_output_path=bias_report_1_output_path,\n",
    "    label='fraud',\n",
    "    headers=train_cols,\n",
    "    dataset_type='text/csv')\n",
    "\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    model_name=model_1_name,\n",
    "    instance_type=train_instance_type,\n",
    "    instance_count=1,\n",
    "    accept_type='text/csv')\n",
    "\n",
    "predictions_config = sagemaker.clarify.ModelPredictedLabelConfig(probability_threshold=0.5)\n",
    "\n",
    "bias_config = sagemaker.clarify.BiasConfig(\n",
    "    label_values_or_threshold=[0],\n",
    "    facet_name='customer_gender_female',\n",
    "    facet_values_or_threshold=[1])\n",
    "\n",
    "# un-comment the code below to run the whole job\n",
    "\n",
    "# if 'clarify_bias_job_1_name' not in locals():\n",
    "\n",
    "#     clarify_processor.run_bias(\n",
    "#         data_config=bias_data_config,\n",
    "#         bias_config=bias_config,\n",
    "#         model_config=model_config,\n",
    "#         model_predicted_label_config=predictions_config,\n",
    "#         pre_training_methods='all',\n",
    "#         post_training_methods='all')\n",
    "\n",
    "#     clarify_bias_job_1_name = clarify_processor.latest_job.name\n",
    "#     %store clarify_bias_job_1_name\n",
    "\n",
    "# else:\n",
    "#     print(f'Clarify job {clarify_bias_job_name} has already run successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results will be stored in `/opt/ml/processing/output/report.pdf`\n",
    "Training to achieve over 90 percent classification accuracy, may be easily possible on an imbalanced classification problem.\n",
    "\n",
    "Thus, expectations developed regarding classification accuracy that are in reality contingent on balanced class distributions will lead to wrong, misleading assumptions and conclusions : misleading the data scientist and viewers into believing that a model has extremely performance when , actually, it does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results of Clarify job (shortcut)\n",
    "Running Clarify on your dataset or model can take ~15 minutes. If you don't have time to run the job, you can view the pre-generated results included with this demo. Otherwise, you can run the job by un-commenting the code in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-generated analysis file...\n",
      "{\n",
      "    \"name\": \"CI\",\n",
      "    \"description\": \"Class Imbalance (CI)\",\n",
      "    \"value\": 0.398\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if 'clarify_bias_job_name' in locals():\n",
    "    s3_client.download_file(Bucket=bucket, Key=f'{prefix}/clarify-output/bias-1/analysis.json', Filename='clarify_output/bias_1/analysis.json')\n",
    "    print(f'Downloaded analysis from previous Clarify job: {clarify_bias_job_name}')\n",
    "else:\n",
    "    print(f'Loading pre-generated analysis file...')\n",
    "\n",
    "with open('clarify_output/bias_1/analysis.json', 'r') as f:\n",
    "        bias_analysis = json.load(f)\n",
    "\n",
    "results = bias_analysis['pre_training_bias_metrics']['facets']['customer_gender_female'][0]['metrics'][1]\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example dataset, the data is biased against females with only 38.9% of the data samples from female customers. We will address this in the next notebook where we show how we mitigate this class imbalance bias. Although we are only addressing Class Imbalance as an exemplar of bias statistics, you can also take into consideration many other factors of bias. For more detail, see : [Fairness Measures for Machine Learning in Finance](https://pages.awscloud.com/rs/112-TZM-766/images/Fairness.Measures.for.Machine.Learning.in.Finance.pdf)\n",
    "\n",
    "for a more detailed example look at [this](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_processing/fairness_and_explainability/fairness_and_explainability.ipynb) github example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more detailed resulst let's look at the generated report, that can be found here: `s3://{bucket}/e2e-fraud-detect/clarify/bias-2/report.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-171928886260/fraud-detect-demo/clarify-output/bias_1/report.pdf to clarify_output/report.pdf\n"
     ]
    }
   ],
   "source": [
    "# #uncomment to copy report and view\n",
    "# !aws s3 cp s3://{bucket}/fraud-detect-demo/clarify-output/bias_1/report.pdf ./clarify_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model-registry'></a>\n",
    "## Deposit Model and Lineage in SageMaker Model Registry\n",
    "\n",
    "[overview](#aud-overview)\n",
    "____\n",
    "Once a useful model has been trained and its artifacts properly associated, the next step is to save the model in a registry for future reference and possible deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Package Group\n",
    "A Model Package Groups holds multiple versions or iterations of a model. Though it is not required to create them for every model in the registry, they help organize various models which all have the same purpose and provide autiomatic versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'mpg_name' not in locals():\n",
    "    mpg_name = prefix\n",
    "    %store mpg_name\n",
    "    print(f'Model Package Group name: {mpg_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_input_dict = {\n",
    "    'ModelPackageGroupName': mpg_name,\n",
    "    'ModelPackageGroupDescription': 'Insurance claim fraud detection'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing Model Package Group: fraud-detect-demo\n"
     ]
    }
   ],
   "source": [
    "matching_mpg = sagemaker_boto_client.list_model_package_groups(NameContains=mpg_name)['ModelPackageGroupSummaryList']\n",
    "\n",
    "if matching_mpg:\n",
    "    print(f'Using existing Model Package Group: {mpg_name}')\n",
    "else:\n",
    "    mpg_response = sagemaker_boto_client.create_model_package_group(**mpg_input_dict)\n",
    "    print(f'Create Model Package Group {mpg_name}: SUCCESSFUL')\n",
    "    %store mpg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Package for trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and upload a metrics report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_report = {'classification_metrics': {}}\n",
    "for metric in training_job_1_info['FinalMetricDataList']:\n",
    "    stat = {metric['MetricName']: {'value': metric['Value']}}\n",
    "    model_metrics_report['classification_metrics'].update(stat)\n",
    "    \n",
    "with open('training_metrics.json', 'w') as f:\n",
    "    json.dump(model_metrics_report, f)\n",
    "    \n",
    "metrics_s3_key = f\"{prefix}/training_jobs/{training_job_1_info['TrainingJobName']}/training_metrics.json\"\n",
    "s3_client.upload_file(Filename='training_metrics.json', Bucket=bucket, Key=metrics_s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the inference spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_inference_spec = InferenceSpecification().get_inference_specification_dict(\n",
    "    ecr_image=training_job_1_info['AlgorithmSpecification']['TrainingImage'],\n",
    "    supports_gpu=False,\n",
    "    supported_content_types=['text/csv'],\n",
    "    supported_mime_types=['text/csv'])\n",
    "\n",
    "mp_inference_spec['InferenceSpecification']['Containers'][0]['ModelDataUrl'] = training_job_1_info['ModelArtifacts']['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model metrics\n",
    "Metrics other than model quality and bias can be defined. See the Boto3 documentation for [creating a model package](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model_package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    'ModelQuality': {\n",
    "        'Statistics': {\n",
    "            'ContentType': 'application/json',\n",
    "            'S3Uri': f's3://{bucket}/{prefix}/{metrics_s3_key}'\n",
    "        }\n",
    "    },\n",
    "    'Bias': {\n",
    "        'Report': {\n",
    "            'ContentType': 'application/json',\n",
    "            'S3Uri': f'{bias_report_1_output_path}/analysis.json'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_input_dict = {\n",
    "    'ModelPackageGroupName': mpg_name,\n",
    "    'ModelPackageDescription': 'XGBoost classifier to detect insurance fraud.',\n",
    "    'ModelApprovalStatus': 'PendingManualApproval',\n",
    "    'ModelMetrics': model_metrics\n",
    "}\n",
    "\n",
    "mp_input_dict.update(mp_inference_spec)\n",
    "mp1_response = sagemaker_boto_client.create_model_package(**mp_input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait until model package is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model package status: Completed\n"
     ]
    }
   ],
   "source": [
    "mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp1_response['ModelPackageArn'])\n",
    "mp_status = mp_info['ModelPackageStatus']\n",
    "\n",
    "while mp_status not in ['Completed', 'Failed']:\n",
    "    time.sleep(5)\n",
    "    mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp1_response['ModelPackageArn'])\n",
    "    mp_status = mp_info['ModelPackageStatus']\n",
    "    print(f'model package status: {mp_status}')\n",
    "print(f'model package status: {mp_status}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View model package in registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ModelPackageGroupName': 'fraud-detect-demo',\n",
       "  'ModelPackageVersion': 2,\n",
       "  'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:171928886260:model-package/fraud-detect-demo/2',\n",
       "  'ModelPackageDescription': 'XGBoost classifier to detect insurance fraud.',\n",
       "  'CreationTime': datetime.datetime(2021, 4, 14, 3, 59, 51, 159000, tzinfo=tzlocal()),\n",
       "  'ModelPackageStatus': 'Completed',\n",
       "  'ModelApprovalStatus': 'PendingManualApproval'},\n",
       " {'ModelPackageGroupName': 'fraud-detect-demo',\n",
       "  'ModelPackageVersion': 1,\n",
       "  'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:171928886260:model-package/fraud-detect-demo/1',\n",
       "  'ModelPackageDescription': 'XGBoost classifier to detect insurance fraud.',\n",
       "  'CreationTime': datetime.datetime(2021, 4, 13, 22, 14, 49, 505000, tzinfo=tzlocal()),\n",
       "  'ModelPackageStatus': 'Completed',\n",
       "  'ModelApprovalStatus': 'PendingManualApproval'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)['ModelPackageSummaryList']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Next Notebook: [Mitigate Bias, Train New Model, Store in Registry](./3-mitigate-bias-train-model2-registry-e2e.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the imbalance, in the next notebook, we over-sample (i.e. upsample) the minority class using [SMOTE (Synthetic Minority Over-sampling Technique)](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html)."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
